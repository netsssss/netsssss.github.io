<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>tag: BeautifulSoup | NetsSsSs Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="NetsSsSs的博客">
<meta property="og:type" content="website">
<meta property="og:title" content="NetsSsSs Blog">
<meta property="og:url" content="http://yoursite.com/tags/BeautifulSoup/index.html">
<meta property="og:site_name" content="NetsSsSs Blog">
<meta property="og:description" content="NetsSsSs的博客">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="NetsSsSs Blog">
<meta name="twitter:description" content="NetsSsSs的博客">
  
    <link rel="alternate" href="/atom.xml" title="NetsSsSs Blog" type="application/atom+xml">
  
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0.css">
  <link rel="stylesheet" href="/lib/fancybox/dist/jquery.fancybox.min.css">
  <link rel="stylesheet" href="/css/main.css">
  <script src="/lib/jquery/dist/jquery.min.js"></script>
  
  
  
  
</head>
<body>
  <div id="wrapper">
    <header id="header" class="clearfix">
	<a id="logo" href="/" title="NetsSsSs Blog">NetsSsSs Blog</a>
	
		<p class="description">不应怠惰</p>
	
	<nav id="nav-menu" class="clearfix">
		<form id="search" method="post" action="./" role="search">
			<input id="search-input" type="text" name="s" class="inputbox" value="搜索" onfocus="if (value =='搜索'){value =''}" onblur="if (value ==''){value='搜索'}">
		</form>
		<ul>
      
				
        <li><a class="main-nav-link" href="/">主页</a></li>
      
				
        <li><a class="main-nav-link" href="/archives">归档</a></li>
      
		</ul>
	</nav>
</header>
    <section id="main" class="clearfix">
  <article class="post-detail">
    <h1 class="post-title"><a href="/">python爬虫的简单实现</a></h1>
    <ul class="post-meta">
  <li><i class="fa fa-user"></i> 作者 NetsSsSs</li>
  <li><i class="fa fa-calendar"></i> 日期 Sep 7</li>
  <li><i class="fa fa-folder"></i> 分类
  
    no_categories
  
  </li>
</ul>
    <div class="post-content">
      <p>新手嘛，爬虫当然是最简单最容易学的吧~我是这么以为的，学了两天，做了这么个东西~<br>网上的都比较喜欢爬这个小说网站<a href="http://www.biqugecom.com/" target="_blank" rel="external">http://www.biqugecom.com/</a> ,试一下咯~<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div></pre></td><td class="code"><pre><div class="line">from bs4 import BeautifulSoup</div><div class="line">import re</div><div class="line">import requests</div><div class="line">import sys</div><div class="line">import time</div><div class="line">import random</div><div class="line">#目前有效20180907</div><div class="line">#先在D盘建一个叫aaa的文件夹</div><div class="line"></div><div class="line">#全局变量</div><div class="line">yuanshiurl = &apos;http://www.biqugecom.com/1/&apos;#原始url</div><div class="line">xinurl = &apos;&apos;#新url</div><div class="line">soupshuming = &apos;&apos;#小说名字</div><div class="line">soupnext = &apos;&apos;#下一章地址</div><div class="line">openshuhao = &apos;13503&apos;#书号</div><div class="line">zhangshu = 1#章数</div><div class="line"></div><div class="line">#交互</div><div class="line">print(&apos;请输入想要下载的小说的书号：&apos;)</div><div class="line">openshuhao = input()</div><div class="line">if openshuhao == &apos;&apos;:</div><div class="line">     print(&apos;未检测到书号，系统将随机抽取&apos;)</div><div class="line">     openshuhao = str(random.randint(1,15000))</div><div class="line">     #openshuhao = str(&apos;13503&apos;)</div><div class="line">print(&apos;下载书号：&apos;+str(openshuhao))</div><div class="line">print(&apos;即将开始下载,请耐心等待...&apos;)</div><div class="line"></div><div class="line">#初始化方法</div><div class="line">def chushihua(shuhao):</div><div class="line">     global soupnext</div><div class="line">     global soupshuming</div><div class="line">     global openshuhao</div><div class="line">     global zhangshu</div><div class="line">     url = yuanshiurl+str(shuhao)+&apos;/&apos;</div><div class="line">     r = requests.get(url)</div><div class="line">     r.encoding = &apos;gbk&apos;</div><div class="line">     soup = BeautifulSoup(r.text,&apos;html.parser&apos;)</div><div class="line">     soupshuming = soup.select(&apos;#info h1&apos;)[0].text#小说名字</div><div class="line">     soupzuozhe = soup.select(&apos;#info p&apos;)[0].text#作者名字</div><div class="line">     soupzuihougengxin = soup.select(&apos;#info p&apos;)[2].text#最后更新时间</div><div class="line">     soupjianjie = soup.select(&apos;#intro&apos;)[0].text#最后更新时间</div><div class="line">     soupzhengwen = soup.select(&apos;dd&apos;)[9].next_siblings</div><div class="line">     soupz = &apos;&apos;</div><div class="line">     for zs in soupzhengwen:</div><div class="line">          soupz +=str(zs)</div><div class="line">     soupzw = BeautifulSoup(soupz,&apos;html.parser&apos;)</div><div class="line">     zhangshu = len(soupzw.select(&apos;dd a&apos;))</div><div class="line">     #写入txt</div><div class="line">     f = open(&apos;D:\\aaa\\&apos;+soupshuming+&apos;.txt&apos;,&apos;ab+&apos;)</div><div class="line">     f.write((str(soupshuming) + &apos;\r\n&apos;).encode(&apos;UTF-8&apos;))</div><div class="line">     f.write((str(soupzuozhe) + &apos;\r\n&apos;).encode(&apos;UTF-8&apos;))</div><div class="line">     f.write((str(soupzuihougengxin) + &apos;\r\n&apos;).encode(&apos;UTF-8&apos;))</div><div class="line">     f.write((&apos;****简介****\r\n&apos;).encode(&apos;UTF-8&apos;))</div><div class="line">     f.write((str(soupjianjie) + &apos;\r\n&apos;).encode(&apos;UTF-8&apos;))</div><div class="line">     f.write((&apos;*************\r\n\r\n&apos;).encode(&apos;UTF-8&apos;))</div><div class="line">     f.close()</div><div class="line">     soupnext = soup.select(&apos;dd a&apos;)[9][&apos;href&apos;].split(&apos;/&apos;)[3]#第一章地址</div><div class="line">     print(&apos;开始下载：&apos;+soupshuming)</div><div class="line">     print(&apos;总章数：&apos;+str(zhangshu))</div><div class="line">     print(&apos;简介：&apos;+str(soupjianjie))</div><div class="line">chushihua(openshuhao)</div><div class="line"></div><div class="line">#单章下载方法</div><div class="line">def downloadxs():</div><div class="line">     global soupnext</div><div class="line">     r =  requests.get(xinurl)</div><div class="line">     r.encoding = &apos;gbk&apos;</div><div class="line">     soup = BeautifulSoup(r.text,&apos;html.parser&apos;)</div><div class="line">     soupname = soup.select(&apos;.bookname h1&apos;)[0].text#章节名称</div><div class="line">     souptext = soup.select(&apos;#content&apos;)[0]#章节内容</div><div class="line">     for ss in souptext.select(&quot;script&quot;):</div><div class="line">          ss.decompose()</div><div class="line">     for ss in souptext.select(&quot;a&quot;):</div><div class="line">          ss.decompose()</div><div class="line">     #soupnext = soup.select(&apos;#pager_next&apos;)[0][&apos;href&apos;]#下一章地址</div><div class="line">     soupnext = soup.select(&apos;.bottem1 a&apos;)[2][&apos;href&apos;]#下一章地址</div><div class="line">     souptext = re.sub(&apos;\s+&apos; ,&apos;\r\n\t&apos;, souptext.text).strip(&apos;\r\n&apos;)</div><div class="line">     f = open(&apos;D:\\aaa\\&apos;+soupshuming+&apos;.txt&apos;,&apos;ab+&apos;)</div><div class="line">     f.write((str(soupname) + &apos;\r\n&apos;).encode(&apos;UTF-8&apos;))</div><div class="line">     f.write((str(souptext) + &apos;\r\n&apos;).encode(&apos;UTF-8&apos;))</div><div class="line">     f.close()</div><div class="line"></div><div class="line">#拼接url方法</div><div class="line">def pinjieurl(shuhao):</div><div class="line">     global xinurl</div><div class="line">     xinurl = yuanshiurl+str(shuhao)+&apos;/&apos;+str(soupnext)</div><div class="line">pinjieurl(openshuhao)</div><div class="line"></div><div class="line">#下载</div><div class="line">def main():</div><div class="line">     for i in range(zhangshu):</div><div class="line">          pinjieurl(openshuhao)</div><div class="line">          downloadxs()</div><div class="line">          time.sleep(0.5)</div><div class="line">          print(&apos;\r下载中：&apos;+str(round(((100/zhangshu)*i),2))+&apos;%，已下载：&apos;+str(i+1)+&apos;章&apos;, end=&apos;&apos;)</div><div class="line">          sys.stdout.flush()</div><div class="line">main()</div></pre></td></tr></table></figure></p>
<p>辣鸡爬虫，只能爬这一个网站，不过原理都是相同的吧（雾）。</p>
<p><img src="https://user-images.githubusercontent.com/33678058/45262625-d8a4e700-b44c-11e8-8641-5cca539f6d2e.jpg" alt=""></p>

    </div>
  </article>


</section>
    <footer id="footer" role="contentinfo">
    <div>&copy; 2019 <a href="/">NetsSsSs Blog</a>.
    Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Designed by <a href="http://rainylog.com" target="_blank">Rainy.</a>
	</div>
</footer><!-- end #footer -->

  </div>
  <script src="/lib/fancybox/dist/jquery.fancybox.min.js"></script>

  <script src="/js/helper.js"></script>
  <script src="/js/_third-party/gitment.js"></script>
</body>
</html>