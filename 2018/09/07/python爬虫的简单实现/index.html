<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="NetsSsSs的博客">
    <meta name="keyword"  content="腾讯">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        python爬虫的简单实现 - NetsSsSs的博客 | NetsSsSs&#39;s Blog
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="/css/gitment.css">
    <!--<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">-->
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
</head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 不应怠惰 </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar">
            <img src="/img/avatar.jpg" />
        </div>
        <div class="name">
            <i>NetsSsSs</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont icon-shouye1"></i>
                    <span>主页</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archives">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>关于</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>
        <div class="index-about-mobile">
            <i> 不应怠惰 </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        python爬虫的简单实现
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2018-09-07 14:29:57</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#python" title="python">python</a>
        <span>/</span>
        
        <a class="tag" href="/tags/#BeautifulSoup" title="BeautifulSoup">BeautifulSoup</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <p>新手嘛，爬虫当然是最简单最容易学的吧~我是这么以为的，学了两天，做了这么个东西~<br>网上的都比较喜欢爬这个小说网站<a href="http://www.biqugecom.com/" target="_blank" rel="external">http://www.biqugecom.com/</a> ,试一下咯~<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div></pre></td><td class="code"><pre><div class="line">from bs4 import BeautifulSoup</div><div class="line">import re</div><div class="line">import requests</div><div class="line">import sys</div><div class="line">import time</div><div class="line">import random</div><div class="line">#目前有效20180907</div><div class="line">#先在D盘建一个叫aaa的文件夹</div><div class="line"></div><div class="line">#全局变量</div><div class="line">yuanshiurl = &apos;http://www.biqugecom.com/1/&apos;#原始url</div><div class="line">xinurl = &apos;&apos;#新url</div><div class="line">soupshuming = &apos;&apos;#小说名字</div><div class="line">soupnext = &apos;&apos;#下一章地址</div><div class="line">openshuhao = &apos;13503&apos;#书号</div><div class="line">zhangshu = 1#章数</div><div class="line"></div><div class="line">#交互</div><div class="line">print(&apos;请输入想要下载的小说的书号：&apos;)</div><div class="line">openshuhao = input()</div><div class="line">if openshuhao == &apos;&apos;:</div><div class="line">     print(&apos;未检测到书号，系统将随机抽取&apos;)</div><div class="line">     openshuhao = str(random.randint(1,15000))</div><div class="line">     #openshuhao = str(&apos;13503&apos;)</div><div class="line">print(&apos;下载书号：&apos;+str(openshuhao))</div><div class="line">print(&apos;即将开始下载,请耐心等待...&apos;)</div><div class="line"></div><div class="line">#初始化方法</div><div class="line">def chushihua(shuhao):</div><div class="line">     global soupnext</div><div class="line">     global soupshuming</div><div class="line">     global openshuhao</div><div class="line">     global zhangshu</div><div class="line">     url = yuanshiurl+str(shuhao)+&apos;/&apos;</div><div class="line">     r = requests.get(url)</div><div class="line">     r.encoding = &apos;gbk&apos;</div><div class="line">     soup = BeautifulSoup(r.text,&apos;html.parser&apos;)</div><div class="line">     soupshuming = soup.select(&apos;#info h1&apos;)[0].text#小说名字</div><div class="line">     soupzuozhe = soup.select(&apos;#info p&apos;)[0].text#作者名字</div><div class="line">     soupzuihougengxin = soup.select(&apos;#info p&apos;)[2].text#最后更新时间</div><div class="line">     soupjianjie = soup.select(&apos;#intro&apos;)[0].text#最后更新时间</div><div class="line">     soupzhengwen = soup.select(&apos;dd&apos;)[9].next_siblings</div><div class="line">     soupz = &apos;&apos;</div><div class="line">     for zs in soupzhengwen:</div><div class="line">          soupz +=str(zs)</div><div class="line">     soupzw = BeautifulSoup(soupz,&apos;html.parser&apos;)</div><div class="line">     zhangshu = len(soupzw.select(&apos;dd a&apos;))</div><div class="line">     #写入txt</div><div class="line">     f = open(&apos;D:\\aaa\\&apos;+soupshuming+&apos;.txt&apos;,&apos;ab+&apos;)</div><div class="line">     f.write((str(soupshuming) + &apos;\r\n&apos;).encode(&apos;UTF-8&apos;))</div><div class="line">     f.write((str(soupzuozhe) + &apos;\r\n&apos;).encode(&apos;UTF-8&apos;))</div><div class="line">     f.write((str(soupzuihougengxin) + &apos;\r\n&apos;).encode(&apos;UTF-8&apos;))</div><div class="line">     f.write((&apos;****简介****\r\n&apos;).encode(&apos;UTF-8&apos;))</div><div class="line">     f.write((str(soupjianjie) + &apos;\r\n&apos;).encode(&apos;UTF-8&apos;))</div><div class="line">     f.write((&apos;*************\r\n\r\n&apos;).encode(&apos;UTF-8&apos;))</div><div class="line">     f.close()</div><div class="line">     soupnext = soup.select(&apos;dd a&apos;)[9][&apos;href&apos;].split(&apos;/&apos;)[3]#第一章地址</div><div class="line">     print(&apos;开始下载：&apos;+soupshuming)</div><div class="line">     print(&apos;总章数：&apos;+str(zhangshu))</div><div class="line">     print(&apos;简介：&apos;+str(soupjianjie))</div><div class="line">chushihua(openshuhao)</div><div class="line"></div><div class="line">#单章下载方法</div><div class="line">def downloadxs():</div><div class="line">     global soupnext</div><div class="line">     r =  requests.get(xinurl)</div><div class="line">     r.encoding = &apos;gbk&apos;</div><div class="line">     soup = BeautifulSoup(r.text,&apos;html.parser&apos;)</div><div class="line">     soupname = soup.select(&apos;.bookname h1&apos;)[0].text#章节名称</div><div class="line">     souptext = soup.select(&apos;#content&apos;)[0]#章节内容</div><div class="line">     for ss in souptext.select(&quot;script&quot;):</div><div class="line">          ss.decompose()</div><div class="line">     for ss in souptext.select(&quot;a&quot;):</div><div class="line">          ss.decompose()</div><div class="line">     #soupnext = soup.select(&apos;#pager_next&apos;)[0][&apos;href&apos;]#下一章地址</div><div class="line">     soupnext = soup.select(&apos;.bottem1 a&apos;)[2][&apos;href&apos;]#下一章地址</div><div class="line">     souptext = re.sub(&apos;\s+&apos; ,&apos;\r\n\t&apos;, souptext.text).strip(&apos;\r\n&apos;)</div><div class="line">     f = open(&apos;D:\\aaa\\&apos;+soupshuming+&apos;.txt&apos;,&apos;ab+&apos;)</div><div class="line">     f.write((str(soupname) + &apos;\r\n&apos;).encode(&apos;UTF-8&apos;))</div><div class="line">     f.write((str(souptext) + &apos;\r\n&apos;).encode(&apos;UTF-8&apos;))</div><div class="line">     f.close()</div><div class="line"></div><div class="line">#拼接url方法</div><div class="line">def pinjieurl(shuhao):</div><div class="line">     global xinurl</div><div class="line">     xinurl = yuanshiurl+str(shuhao)+&apos;/&apos;+str(soupnext)</div><div class="line">pinjieurl(openshuhao)</div><div class="line"></div><div class="line">#下载</div><div class="line">def main():</div><div class="line">     for i in range(zhangshu):</div><div class="line">          pinjieurl(openshuhao)</div><div class="line">          downloadxs()</div><div class="line">          time.sleep(0.5)</div><div class="line">          print(&apos;\r下载中：&apos;+str(round(((100/zhangshu)*i),2))+&apos;%，已下载：&apos;+str(i+1)+&apos;章&apos;, end=&apos;&apos;)</div><div class="line">          sys.stdout.flush()</div><div class="line">main()</div></pre></td></tr></table></figure></p>
<p>辣鸡爬虫，只能爬这一个网站，不过原理都是相同的吧（雾）。</p>

        
            <div class="donate-container">
    <div class="donate-button">
        <button id="donate-button">赞赏</button>
    </div>
    <div class="donate-img-container hide" id="donate-img-container">
        <img id="donate-img" src="" data-src="/img/donate.jpg">
        <p> 感谢鼓励 </p>
    </div>
</div>
        
        <div id="comment-container">
        </div>
    </div>
</div>
    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        
        <li>
            <a target="_blank" href="https://www.zhihu.com/people/ting-feng-mu-yu-59">
                            <span class="fa-stack fa-lg">
                                 <i class="iconfont icon-zhihu"></i>
                            </span>
            </a>
        </li>
        

        
        <li>
            <a target="_blank" href="http://weibo.com/5022761699">
                            <span class="fa-stack fa-lg">
                                  <i class="iconfont icon-weibo"></i>
                            </span>
            </a>
        </li>
        

        
        <li>
            <a target="_blank" href="https://www.facebook.com/netsssss">
                            <span class="fa-stack fa-lg">
                                <i class="iconfont icon-facebook"></i>
                            </span>
            </a>
        </li>
        

        
        <li>
            <a target="_blank"  href="https://github.com/netsssss">
                            <span class="fa-stack fa-lg">
                                <i class="iconfont icon-github"></i>
                            </span>
            </a>
        </li>
        

        

    </ul>
    
    <p>
        <span>/</span>
        
        <span><a href="http://www.baidu.com">baidu</a></span>
        <span>/</span>
        
        <span><a href="http://www.bilibili.com/">bilibili</a></span>
        <span>/</span>
        
        <span><a href="https://fanyi.baidu.com">fanyi</a></span>
        <span>/</span>
        
    </p>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a href="https://hexo.io/">Hexo</a>  Theme <a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<script src="/js/gitment.js"></script>
<script>
    var gitment = new Gitment({
        id: 'python爬虫的简单实现',
        owner: 'netsssss',
        repo: 'netsssss.github.io',
        oauth: {
            client_id: 'b3dff31cb64aefc16b5c',
            client_secret: '2ee483f0cb98833e3fd10bf56ecae4158e08a6e2',
        },
    })
    gitment.render('comment-container')
</script>

</html>
